# 项目说明

本项目实现了基于智联招聘网站的职位数据爬取，分为两个阶段：初始数据爬取和详细数据抓取。

## 技术栈与工具
1. **Python 数据爬取技术**：
   - 使用 `requests` 和 `BeautifulSoup` 获取页面内容并解析基础职位信息。
   - 使用 `pyppeteer` 和 `asyncio` 异步爬取详细信息，提升效率。
2. **并发控制**：
   - `tqdm` 提供爬取进度条显示。
   - 使用 `asyncio.Semaphore` 限制每个浏览器实例的并发任务数量。
   - `nest_asyncio` 解决多任务事件循环冲突问题。
3. **浏览器自动化**：
   - `DrissionPage`（基于 Selenium 和 Chromium）用于处理动态加载的网页。
   - `pyppeteer` 作为无头浏览器用于详细信息抓取。
4. **数据处理与存储**：
   - `pandas` 用于处理数据表格，并将结果保存为 CSV 文件。

## 功能实现
1. **阶段 1：基础数据爬取**：
   - 从智联招聘抓取多个职位的列表信息，包括职位名称、公司名称、薪资范围、工作地点、经验要求、学历要求等。
   - 通过 `DrissionPage` 动态模拟用户输入，实现搜索结果的自动化获取。

2. **阶段 2：详细信息爬取**：
   - 读取阶段 1 的基础数据，利用职位链接进一步爬取每个职位的详细信息，如：
     - 职位描述
     - 招聘人数
     - 发布时间
   - 使用 `pyppeteer` 实现异步爬取，大幅提升爬取效率。

## 输出结果
最终数据整合后保存为 CSV 文件，包含所有爬取的职位基础信息及详细信息，便于后续数据分析和处理。


- **动态加载处理**：结合无头浏览器和异步技术，解决传统爬取方式难以应对的问题。
- **高效并发**：支持多浏览器实例并行工作，显著提升爬取效率。
- **数据可视化**：生成清晰的 CSV 文件，便于分析和展示。


